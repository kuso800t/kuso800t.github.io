提供いただいた `sitemap.xml` および `robots.txt` の内容とcurlの実行結果を拝見しました。

curlの実行結果から、以下の点が確認できます。

* `https://kuso800t.github.io/sitemap.xml` および `https://kuso800t.github.io/robots.txt` は、どちらも **HTTP/2 200 OK** で取得できています。これは、ファイル自体が存在し、Googleのクローラーがアクセスできる状態にあることを示しています。
* `sitemap.xml` の `Content-Type` は `application/xml` となっており、正しい形式で配信されています。
* `robots.txt` では `User-agent: Googlebot` および `User-agent: *` のどちらに対しても、サイトマップのパスである `/sitemap.xml` は `Disallow` されていません。また、Sitemapディレクティブも正しく記述されています。
* `sitemap.xml` のXML形式も基本的な構文は問題なさそうです。一部 `lastmod` がないURLもありますが、これは必須ではありません。サイトルートのURLが重複していますが、これが直接的な読み込みエラーの原因になる可能性は低いです。

これらの情報から判断する限り、**サイトマップファイル自体に問題がある、または `robots.txt` でアクセスが拒否されているといった直接的な原因は見当たりません。**

もしSearch Consoleで「読み込めませんでした」と表示されている場合、他の原因が考えられます。

考えられること：

1.  **送信直後でまだ処理が完了していない:** サイトマップを送信したばかりの場合、Googleがクロールして内容を処理するまでに時間がかかることがあります。
2.  **サイト側の一時的な問題:** Googleがサイトマップをクロールしようとしたタイミングで、サーバーに一時的な負荷がかかっていたり、ネットワークの問題が発生していたりした可能性があります。
3.  **Search Console側の一時的な表示問題:** まれにSearch Consoleの表示が最新の状態になっていないこともあります。
4.  **サイトマップ内のURLに問題が多い（ただし可能性は低い）:** サイトマップ自体は読み込めても、その中に含まれる多数のURLがエラーになる場合、「読み込めませんでした」ではなく「エラーがあります」と表示されることが多いですが、ゼロではありません。

**推奨される対処法:**

* **しばらく様子を見る:** サイトマップを送信したばかりであれば、数時間から一日程度待ってみてください。
* **再度送信してみる:** 時間をおいても状況が変わらない場合、一度Search Consoleからサイトマップを削除し、再度追加・送信してみてください。
* **URL検査ツールで確認:** Search ConsoleのURL検査ツールを使って、サイトマップのURL (`https://kuso800t.github.io/sitemap.xml`) を検査し、GoogleがそのURLをどのように認識しているか確認してみるのも有効です。

提供された情報からは直接的なエラー原因は見つけられませんでしたが、上記のいずれかの理由で一時的に読み込めない状態になっているのかもしれません。しばらく様子を見て、改善されない場合は再度状況を確認してみてください。